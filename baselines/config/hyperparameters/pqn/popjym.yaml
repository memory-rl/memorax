# @package _global_

total_timesteps: 20_000_000
num_train_steps: 500_000
num_eval_steps: 10_000

algorithm:
  num_envs: 128
  num_eval_envs: 0
  num_steps: 128
  num_minibatches: 8
  update_epochs: 4
  gamma: 0.99
  td_lambda: 0.95

epsilon_schedule:
  init_value: 1.0
  end_value: 0.05
  transition_steps: ${eval:"0.25 * ${total_timesteps}"}

optimizer:
  learning_rate: 5e-5
torso:
  features: 256
