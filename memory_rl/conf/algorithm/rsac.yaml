name: rsac
policy_lr:            3e-4
q_lr:           3e-4
temp_lr:             3e-4
num_envs:            1
num_eval_envs:       1
buffer_size:         1_000_000
gamma:               0.99
tau:                 5e-3
train_frequency:     1
target_update_frequency: 1
batch_size:          128
hidden_dims:         [256, 256]
actor_cell_size:           256
critic_cell_size:           256
sample_sequence_length:     1
init_temperature:    1.0
policy_log_std_min: -5
policy_log_std_max: 2
policy_final_fc_init_scale: 1e-3
target_entropy_multiplier: 1.0
max_action:          1.0
backup_entropy:      true
learning_starts:     5_000
