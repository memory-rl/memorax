total_timesteps: 5000000
num_train_steps: 100000
evaluate_every: 100000
seed: 0
num_seeds: 5
logger:
  _target_: memory_rl.loggers.Logger
  _convert_: all
  loggers:
    console:
      _target_: memory_rl.loggers.ConsoleLogger
      title: Memory RL
      name: ppo
      total_timesteps: 5000000
      refresh_per_second: 1
      env_id: Breakout-MinAtar
    file:
      _target_: memory_rl.loggers.FileLogger
      algorithm: ppo
      environment: Breakout-MinAtar
      seed: 0
      directory: /home/farr/memory-rl/logs
algorithm:
  actor:
    feature_extractor:
      _target_: memory_rl.networks.SharedFeatureExtractor
      extractor:
        _target_: memory_rl.networks.MLP
        features:
        - 128
        kernel_init:
          _target_: flax.linen.initializers.orthogonal
          scale: 1.414
    torso:
      _target_: memory_rl.networks.MLP
      features:
      - 128
      kernel_init:
        _target_: flax.linen.initializers.orthogonal
        scale: 1.414
  critic:
    feature_extractor:
      _target_: memory_rl.networks.SharedFeatureExtractor
      extractor:
        _target_: memory_rl.networks.MLP
        features:
        - 128
        kernel_init:
          _target_: flax.linen.initializers.orthogonal
          scale: 1.414
    torso:
      _target_: memory_rl.networks.MLP
      features:
      - 128
      kernel_init:
        _target_: flax.linen.initializers.orthogonal
        scale: 1.414
  name: ppo
  learning_rate: 0.005
  num_envs: 64
  num_eval_envs: 10
  num_steps: 64
  anneal_lr: true
  gamma: 0.99
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 8
  batch_size: 4096
  normalize_advantage: true
  clip_coef: 0.2
  clip_vloss: true
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  learning_starts: 0
environment:
  env_id: Breakout-MinAtar
  wrappers:
  - _target_: gymnax.wrappers.FlattenObservationWrapper
