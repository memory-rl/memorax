name: rsac_old
policy_lr:            3e-4
q_lr:           3e-4
temp_lr:             3e-4
num_envs:            5
num_eval_envs:       10
buffer_size:         1_000_000
gamma:               0.99
tau:                 5e-3
train_frequency:     5
target_update_frequency: 1
batch_size:          256
hidden_dims:         [256]
actor_cell_size:           256
critic_cell_size:           256
sample_sequence_length:     8
init_temperature:    1.0
policy_log_std_min: -10
policy_log_std_max: 2
policy_final_fc_init_scale: 1e-3
target_entropy_multiplier: 0.5
max_action:          1.0
backup_entropy:      true
learning_starts:     5_000
