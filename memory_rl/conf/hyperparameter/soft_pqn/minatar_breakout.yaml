# @package _global_

total_timesteps:     10_000_000
num_train_steps:     100_000
evaluate_every:      1_000_000

algorithm:
  learning_rate:       5e-4
  alpha_lr:            3e-4
  beta_lr:             1e-3
  num_envs:            128
  num_eval_envs:       10
  num_steps:           32
  num_minibatches:     32
  update_epochs:       2
  td_lambda:           0.65
  gamma:               0.99
  batch_size:          ${eval:${.num_envs}*${.num_steps}}
  max_grad_norm:       10.0
  initial_alpha:       -1.0
  initial_beta:        0.0
  kl_target:           0.02

  learning_starts:     0

  feature_extractor:
    extractor:
      _target_: memory_rl.networks.CNN
      features:        [16]
      kernel_sizes:    [[3, 3]]
      strides:         [[1, 1]]
      normalizer:
        _target_: flax.linen.LayerNorm

environment:
  wrappers: []
