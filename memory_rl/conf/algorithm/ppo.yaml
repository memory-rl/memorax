# Algorithm specific arguments
name: ppo
learning_rate: 5e-3
num_envs: 64
num_eval_envs: 64
num_steps: 128
anneal_lr: False
gamma: 0.99
gae_lambda: 0.95
num_minibatches: 8
update_epochs: 8
normalize_advantage: True
clip_coef: 0.2
clip_vloss: False
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
learning_starts: 0
hidden_dims: [256]

