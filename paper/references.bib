% ============================================================================
% Memorax Paper References
% ============================================================================

% --------------------------------------------------------------------------
% POMDP Benchmarks
% --------------------------------------------------------------------------

@inproceedings{morad2023popgym,
  title     = {{POPGym}: Benchmarking Partially Observable Reinforcement Learning},
  author    = {Morad, Steven and Kortvelesy, Ryan and Bettini, Matteo and Liwicki, Stephan and Prorok, Amanda},
  booktitle = {The Eleventh International Conference on Learning Representations},
  year      = {2023},
  url       = {https://openreview.net/forum?id=chDrutUTs0K},
}

@article{tao2025pobax,
  title   = {Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains},
  author  = {Tao, Ruo Yu and Guo, Kaicheng and Allen, Cameron and Konidaris, George},
  journal = {Reinforcement Learning Journal},
  year    = {2025},
  url     = {https://arxiv.org/abs/2508.00046},
}

@article{wang2025popgymarcade,
  title   = {Investigating Memory in {RL} with {POPGym} Arcade},
  author  = {Wang, Zekang and He, Zhe and Zhang, Borong and Toledo, Edan and Morad, Steven},
  journal = {arXiv preprint arXiv:2503.01450},
  year    = {2025},
  url     = {https://arxiv.org/abs/2503.01450},
}

% --------------------------------------------------------------------------
% Sequence Models
% --------------------------------------------------------------------------

@inproceedings{gu2024mamba,
  title     = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author    = {Gu, Albert and Dao, Tri},
  booktitle = {Proceedings of the 41st International Conference on Machine Learning},
  year      = {2024},
  url       = {https://arxiv.org/abs/2312.00752},
}

@inproceedings{gu2022s4,
  title     = {Efficiently Modeling Long Sequences with Structured State Spaces},
  author    = {Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle = {The Tenth International Conference on Learning Representations},
  year      = {2022},
  url       = {https://arxiv.org/abs/2111.00396},
}

@inproceedings{smith2023s5,
  title     = {Simplified State Space Layers for Sequence Modeling},
  author    = {Smith, Jimmy T.H. and Warrington, Andrew and Linderman, Scott},
  booktitle = {The Eleventh International Conference on Learning Representations},
  year      = {2023},
  url       = {https://openreview.net/forum?id=Ai8Hw3AXqks},
}

@inproceedings{orvieto2023lru,
  title     = {Resurrecting Recurrent Neural Networks for Long Sequences},
  author    = {Orvieto, Antonio and Smith, Samuel L. and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  year      = {2023},
  url       = {https://arxiv.org/abs/2303.06349},
}

@inproceedings{beck2024xlstm,
  title     = {{xLSTM}: Extended Long Short-Term Memory},
  author    = {Beck, Maximilian and P{\"o}ppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, G{\"u}nter and Brandstetter, Johannes and Hochreiter, Sepp},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {37},
  year      = {2024},
  url       = {https://arxiv.org/abs/2405.04517},
}

@article{feng2024minGRU,
  title   = {Were {RNNs} All We Needed?},
  author  = {Feng, Leo and Tung, Frederick and Ahmed, Mohamed Osama and Bengio, Yoshua and Hajimirsadeghi, Hossein},
  journal = {arXiv preprint arXiv:2410.01201},
  year    = {2024},
  url     = {https://arxiv.org/abs/2410.01201},
}

@inproceedings{morad2023ffm,
  title     = {Reinforcement Learning with Fast and Forgetful Memory},
  author    = {Morad, Steven and Kortvelesy, Ryan and Liwicki, Stephan and Prorok, Amanda},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {36},
  year      = {2023},
  url       = {https://arxiv.org/abs/2310.04128},
}

@inproceedings{katharopoulos2020lineartransformers,
  title     = {Transformers are {RNNs}: Fast Autoregressive Transformers with Linear Attention},
  author    = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.16236},
}

@inproceedings{vaswani2017attention,
  title     = {Attention is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017},
  url       = {https://arxiv.org/abs/1706.03762},
}

@inproceedings{parisotto2020gtrxl,
  title     = {Stabilizing Transformers for Reinforcement Learning},
  author    = {Parisotto, Emilio and Song, H. Francis and Rae, Jack W. and Pascanu, Razvan and Gulcehre, Caglar and Jayakumar, Siddhant M. and Jaderberg, Max and Kaufman, Raphael Lopez and Clark, Aidan and Noury, Seb and Botvinick, Matthew M. and Heess, Nicolas and Hadsell, Raia},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  year      = {2020},
  url       = {https://arxiv.org/abs/1910.06764},
}

@article{hochreiter1997lstm,
  title   = {Long Short-Term Memory},
  author  = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal = {Neural Computation},
  volume  = {9},
  number  = {8},
  pages   = {1735--1780},
  year    = {1997},
  doi     = {10.1162/neco.1997.9.8.1735},
}

@inproceedings{cho2014gru,
  title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical Machine Translation},
  author    = {Cho, Kyunghyun and van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing},
  pages     = {1724--1734},
  year      = {2014},
  doi       = {10.3115/v1/D14-1179},
}

@inproceedings{le2025shm,
  title     = {Stable {Hadamard} Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning},
  author    = {Le, Hung and Do, Kien and Nguyen, Dung and Gupta, Sunil and Venkatesh, Svetha},
  booktitle = {The Thirteenth International Conference on Learning Representations},
  year      = {2025},
  url       = {https://arxiv.org/abs/2410.10132},
}

% --------------------------------------------------------------------------
% RL Algorithms
% --------------------------------------------------------------------------

@article{schulman2016gae,
  title   = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  author  = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1506.02438},
  year    = {2016},
  url     = {https://arxiv.org/abs/1506.02438},
}

@article{mnih2015dqn,
  title   = {Human-level control through deep reinforcement learning},
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riesenhuber, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal = {Nature},
  volume  = {518},
  number  = {7540},
  pages   = {529--533},
  year    = {2015},
}

@inproceedings{haarnoja2018sac,
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author    = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages     = {1861--1870},
  year      = {2018},
}

@article{schulman2017ppo,
  title   = {Proximal Policy Optimization Algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017},
  url     = {https://arxiv.org/abs/1707.06347},
}

@inproceedings{kapturowski2019r2d2,
  title     = {Recurrent Experience Replay in Distributed Reinforcement Learning},
  author    = {Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
  booktitle = {The Seventh International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=r1lyTjAqYX},
}

@inproceedings{gallici2025pqn,
  title     = {Simplifying Deep Temporal Difference Learning},
  author    = {Gallici, Matteo and Fellows, Mattie and Ellis, Benjamin and Pou, Bartomeu and Masmitja, Ivan and Foerster, Jakob Nicolaus and Martin, Mario},
  booktitle = {The Thirteenth International Conference on Learning Representations},
  year      = {2025},
  url       = {https://arxiv.org/abs/2407.04811},
}

% --------------------------------------------------------------------------
% RL Libraries / Frameworks
% --------------------------------------------------------------------------

@article{huang2022cleanrl,
  title   = {{CleanRL}: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
  author  = {Huang, Shengyi and Dossa, Rousslan Fernand Julien and Ye, Chang and Braga, Jeff and Chakraborty, Dipam and Mehta, Kinal and Ara{\'u}jo, Jo{\~a}o G.M.},
  journal = {Journal of Machine Learning Research},
  volume  = {23},
  number  = {274},
  pages   = {1--18},
  year    = {2022},
  url     = {http://jmlr.org/papers/v23/21-1342.html},
}

@article{suarez2024pufferlib,
  title   = {{PufferLib}: Making Reinforcement Learning Libraries and Environments Play Nice},
  author  = {Suarez, Joseph},
  journal = {arXiv preprint arXiv:2406.12905},
  year    = {2024},
  url     = {https://arxiv.org/abs/2406.12905},
}

@misc{toledo2024stoix,
  title   = {Stoix: A research-friendly codebase for fast experimentation of single-agent reinforcement learning in {JAX}},
  author  = {Toledo, Edan},
  year    = {2024},
  url     = {https://github.com/EdanToledo/Stoix},
  doi     = {10.5281/zenodo.10916257},
}

@misc{lu2023purejaxrl,
  title  = {{PureJaxRL}: Really Fast End-to-End {JAX} {RL} Implementations},
  author = {Lu, Chris},
  year   = {2023},
  url    = {https://github.com/luchris429/purejaxrl},
}

% --------------------------------------------------------------------------
% Other
% --------------------------------------------------------------------------

@misc{jax2018github,
  title   = {{JAX}: Composable Transformations of {P}ython+{N}um{P}y Programs},
  author  = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and Vander{P}las, Jake and Wanderman-{M}ilne, Skye and Zhang, Qiao},
  year    = {2018},
  url     = {http://github.com/jax-ml/jax},
}

@misc{flax2024github,
  title   = {Flax: A Neural Network Library and Ecosystem for {JAX}},
  author  = {Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and van Zee, Marc},
  year    = {2024},
  url     = {http://github.com/google/flax},
}

@inproceedings{agarwal2021rliable,
  title     = {Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author    = {Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C. and Bellemare, Marc G.},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {34},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.13264},
}

@techreport{blelloch1990prefix,
  title       = {Prefix Sums and Their Applications},
  author      = {Blelloch, Guy E.},
  institution = {School of Computer Science, Carnegie Mellon University},
  number      = {CMU-CS-90-190},
  year        = {1990},
  url         = {https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf},
}

@article{kaelbling1998pomdp,
  title   = {Planning and Acting in Partially Observable Stochastic Domains},
  author  = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
  journal = {Artificial Intelligence},
  volume  = {101},
  number  = {1--2},
  pages   = {99--134},
  year    = {1998},
  doi     = {10.1016/S0004-3702(98)00023-X},
}

@article{sullivan2024syllabus,
  title   = {Syllabus: Portable Curricula for Reinforcement Learning Agents},
  author  = {Sullivan, Ryan and P{\'e}goud, Ryan and Rehman, Ameen Ur and Yang, Xinchen and Huang, Junyun and Verma, Aayush and Mitra, Nistha and Dickerson, John P.},
  journal = {arXiv preprint arXiv:2411.11318},
  year    = {2024},
  url     = {https://arxiv.org/abs/2411.11318},
}

@inproceedings{hausknecht2015drqn,
  title     = {Deep Recurrent {Q}-Learning for Partially Observable {MDPs}},
  author    = {Hausknecht, Matthew and Stone, Peter},
  booktitle = {AAAI Fall Symposium on Sequential Decision Making for Intelligent Agents},
  year      = {2015},
  url       = {https://arxiv.org/abs/1507.06527},
}

@misc{morad2025memax,
  title  = {Memax: Deep Memory and Sequence Models in {JAX}},
  author = {Morad, Steven and Toledo, Edan and Kortvelesy, Ryan and He, Zhe},
  year   = {2025},
  url    = {https://github.com/smorad/memax},
}
